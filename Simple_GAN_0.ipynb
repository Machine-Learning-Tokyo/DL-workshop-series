{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple_GAN_0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Machine-Learning-Tokyo/DL-workshop-series/blob/master/Simple_GAN_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "14vb70Ys_sxa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Simple GAN"
      ]
    },
    {
      "metadata": {
        "id": "bwOiOQAY_uyh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is a simple GAN with fully connected layers for both generator and discriminator. It is trained on mnist dataset."
      ]
    },
    {
      "metadata": {
        "id": "KlRx5ymdZG0E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ]
    },
    {
      "metadata": {
        "id": "tHZUZmOUNEoJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, BatchNormalization, Reshape, Flatten\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.datasets import mnist\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uvvPV_WIZoR2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to build the generator"
      ]
    },
    {
      "metadata": {
        "id": "TMA9U2CF_6wu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Generator is a model that takes as input noise and outputs an image.\n",
        "\n",
        "The noise comes from a normal distribution (0, 1) and is a vector of size `noise_size`.\n",
        "\n",
        "The generated image is an array of shape `img_shape`.\n",
        "\n",
        "The presented generator model is a simple network consisted of 3 blocks. Each block has a [Dense](https://keras.io/layers/core/#dense) layer, followed by a [BatchNormalization](https://keras.io/layers/normalization/#batchnormalization) and a [LeakyReLU](https://keras.io/layers/advanced-activations/#leakyrelu)."
      ]
    },
    {
      "metadata": {
        "id": "6gqJ4ZrmNHve",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_generator(noise_size, img_shape):\n",
        "  \"\"\"\n",
        "  function that takes as input\n",
        "  the noise_size (integer) and the img_shape (tuple of integers)\n",
        "  and returns a keras Model.\n",
        "  The model has 3 blocks of Dense, BatchNormalization and LeakyReLU layers.\n",
        "  The units at the Dense layers are 256, 512 and 1024 respectively.\n",
        "  The alpha parameter at the LeakyReLU layers is 0.2.\n",
        "  The activation of the last layer is tanh.\n",
        "  The model (generator) takes as input a tensor of shape (noise_size,)\n",
        "  and returns a tensor of shape img_shape.\n",
        "  \"\"\"\n",
        "  \n",
        "  noise = Input((noise_size,))\n",
        "  \n",
        "  x = Dense(256)(noise)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  \n",
        "  x = Dense(512)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  \n",
        "  x = Dense(1024)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  \n",
        "  x = Dense(np.prod(img_shape), activation='tanh')(x)\n",
        "  img = Reshape(img_shape)(x)\n",
        "  \n",
        "  generator = Model(noise, img)\n",
        "  return generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ooEwRbP8eLgw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to build the discriminator"
      ]
    },
    {
      "metadata": {
        "id": "h9xjHSFt_9o2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Discriminator is a model that takes as input an image and outputs a number. This number (`validity`) is in [0, 1] and indicates the belief of the discriminator about the validity of the image.\n",
        "- High value means that the discriminator \"thinks\" that the given image is a real image:\n",
        "- Low value means that the discriminator \"thinks\" that the given image is a generated (fake) one.\n",
        "\n",
        "The presented discriminator model is a simple network consisted of 3 blocks. Each block has a Dense layer, followed by a LeakyReLU. One could also add a BatchNormalization layer as in the generator case."
      ]
    },
    {
      "metadata": {
        "id": "UysJTIlPOlZS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_discriminator(img_shape):\n",
        "  \"\"\"\n",
        "  function that takes as input the img_shape (tuple of integers)\n",
        "  and returns a keras Model.\n",
        "  The model has 3 blocks of Dense and LeakyReLU layers.\n",
        "  The units at the Dense layers are 1024, 512, and 256 respectively.\n",
        "  The alpha parameter at the LeakyReLU layers is 0.2\n",
        "  The activation of the last layer is sigmoid.\n",
        "  The model (discriminator) takes as input a tensor of shape img_shape\n",
        "  and returns a tensor of shape 1\n",
        "  \"\"\"\n",
        "  \n",
        "  img = Input(img_shape)\n",
        "  f_img = Flatten()(img)\n",
        "  \n",
        "  x = Dense(1024)(f_img)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  \n",
        "  x = Dense(512)(x)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  \n",
        "  x = Dense(256)(x)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  \n",
        "  validity = Dense(1, activation='sigmoid')(x)\n",
        "  \n",
        "  discriminator = Model(img, validity)\n",
        "  return discriminator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uxDM6ldueOte",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to compile the models"
      ]
    },
    {
      "metadata": {
        "id": "KC2cVZCJ__8F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In keras, one has to compile the models before training them. [Compile](https://keras.io/models/model/) method takes as inputs the optimizer, the loss function and optional metrics.\n",
        "\n",
        "In our case, we use:\n",
        "- [Adam](https://keras.io/optimizers/#adam) optimizer\n",
        "- [binary_crossentropy](https://keras.io/losses/#binary_crossentropy) as a loss function\n",
        "- (binary) [accuracy](https://keras.io/metrics/#binary_accuracy) as a metric for the discriminator.\n",
        "\n",
        "We first compile the discriminator model. Then we \"freeze\" it (make its layers non trainable) and construct a new model. The new model (combined) is the combination of the generator and the discriminator. The combined model takes as input noise, passes it through the generator, takes the generated image and sends it to the discriminator. The disciminator outputs the validity which is the output of the combined model. Finally, we compile the combined model."
      ]
    },
    {
      "metadata": {
        "id": "gEfTuy93PRNb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_compiled_models(generator, discriminator, noise_size):\n",
        "  \"\"\"\n",
        "  function that takes as input\n",
        "  the generator (keras.Model)\n",
        "  the discriminator (keras.Model)\n",
        "  and the noise_size (integer)\n",
        "  and return the generator, the compiled discriminator and the compiled comnbined models.\n",
        "  The combined model takes as input noise (tensor of shape (noise_size,))\n",
        "  and outputs the validity (output of the discriminator)\n",
        "  of the internally generated image (output of the generator).\n",
        "  For both models the optimizer is Adam with learning rate 0.0002 and beta_1 0.5\n",
        "  and the loss function is binary_crossentropy.\n",
        "  The discriminator has accuracy as metric.\n",
        "  \"\"\"\n",
        "  \n",
        "  optimizer = Adam(0.0002, 0.5)\n",
        "  \n",
        "  discriminator.compile(optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  discriminator.trainable = False\n",
        "  \n",
        "  noise = Input((noise_size,))\n",
        "  img = generator(noise)\n",
        "  validity = discriminator(img)\n",
        "  combined = Model(noise, validity)\n",
        "  \n",
        "  combined.compile(optimizer, loss='binary_crossentropy')\n",
        "  \n",
        "  return generator, discriminator, combined"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ocu71YfmeSIH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to sample and save generated images"
      ]
    },
    {
      "metadata": {
        "id": "YXRv1tg6ACW9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is a function that produces some sampled images using the generator and saves them at a folder. This way one can obtain the visual results of the training procedure."
      ]
    },
    {
      "metadata": {
        "id": "X4-ejg8UTwqV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample_imgs(generator, noise_size, step):\n",
        "  \"\"\"\n",
        "  function that takes as input the generator (keras.Model), the noise_size (integer)\n",
        "  and the step (integer) and generates and saves samples of the generated images.\n",
        "  The images are in a 5x5 grid and are saved at ./images/{step}.png\n",
        "  \"\"\"\n",
        "  \n",
        "  r, c = 5, 5\n",
        "  noise = np.random.normal(0, 1, (r*c, noise_size))\n",
        "  imgs = generator.predict(noise)\n",
        "  imgs = imgs / 2 + 0.5\n",
        "  \n",
        "  fig, axs = plt.subplots(r, c)\n",
        "  cnt = 0\n",
        "  for i in range(r):\n",
        "    for j in range(c):\n",
        "      axs[i, j].imshow(imgs[cnt], cmap='gray')\n",
        "      axs[i, j].axis('off')\n",
        "      cnt += 1\n",
        "  fig.savefig('./images/%d.png' % step)\n",
        "  plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K3ofIxpleVoc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to train the models"
      ]
    },
    {
      "metadata": {
        "id": "Wnl63LyXAEl0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is the function responsible for the training of our GAN. First, we define our real data, in this case we use the [mnist](https://keras.io/datasets/#mnist-database-of-handwritten-digits) dataset. Then we enter the training loop:\n",
        "\n",
        "- First we train the discriminator for one batch. The discriminator has to be trained at both the real data and the generated data. when training a model, we have to give the target values, so that it can compute the declination from its target (loss) and based on this to become better throuth an optimization method. Since, as we mentioned before, high validity values indicate that the given images are real and low values indicate generated (fake) images, we want the discriminator to ideally output:\n",
        " - values close to 1 for the given real images\n",
        " - values close to 0 for the given generated images\n",
        "- After the discriminator we train the combined model. For the combined model we generate images and evaluate their validity through the discriminator. Since we want the generated images to be like the real ones, we want their validity to be ideally close to one. In order to achieve this, we set the target values for the validity of the generated images to be **one**. This is a bit tricky, since when we trained the discriminator, we set the target values for the generated images to zero. The difference is that now we train the generator and thus we want the generated images to be as close to the real ones as possible. And the only way to pass it to the model is by setting the target values for the validity to be the same as those of the real images. However, we don't want the disciminator to \"think\" that the generated images are indeed real. This is why we \"froze\" the discriminator at the combined model. This way, the disciminator will not be trained to recognize the generated images as real ones, and the generator will be trained to produce images as close as possible to the real ones."
      ]
    },
    {
      "metadata": {
        "id": "wHI7xwGMQRAW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(models, noise_size, img_shape, batch_size, steps):\n",
        "  \"\"\"\n",
        "  function that takes as input the models (tuple of generator, discriminator, combined),\n",
        "  the noise_size, the img_shape, the batch_size and the steps and trains the models\n",
        "  for this number of steps on batches of size batch_size.\n",
        "  The training data are from mnist (keras.datasets).\n",
        "  For preprocessing, the data are normalized in [-1, 1] (original in [0, 255]).\n",
        "  Every 100 steps the models loss and accuracy is printed and samples are saved.\n",
        "  \"\"\"\n",
        "  generator, discriminator, combined = models\n",
        "  #get real data\n",
        "  (X_train, _), (X_val, _) = mnist.load_data()\n",
        "  mnist_imgs = np.concatenate((X_train, X_val)) / 127.5 - 1\n",
        "  \n",
        "  for step in range(1, steps + 1):\n",
        "    # train discriminator\n",
        "    inds = np.random.randint(0, mnist_imgs.shape[0], batch_size)\n",
        "    real_imgs = mnist_imgs[inds]\n",
        "    real_validity = np.ones(batch_size)\n",
        "    \n",
        "    noise = np.random.normal(0, 1, (batch_size, noise_size))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "    gen_validity = np.zeros(batch_size)\n",
        "    \n",
        "    r_loss = discriminator.train_on_batch(real_imgs, real_validity)\n",
        "    g_loss = discriminator.train_on_batch(gen_imgs, gen_validity)\n",
        "    disc_loss = np.add(r_loss, g_loss) / 2\n",
        "    \n",
        "    # train generator\n",
        "    noise = np.random.normal(0, 1, (batch_size, noise_size))\n",
        "    gen_validity = np.ones(batch_size)\n",
        "    gen_loss = combined.train_on_batch(noise, gen_validity)\n",
        "    \n",
        "    #print progress\n",
        "    if step % 100 == 0:\n",
        "      print('step: %d, D_loss: %f, D_accuracy: %.2f%%, G_loss: %f' % (step, disc_loss[0],\n",
        "                                                                      disc_loss[1] * 100, gen_loss))\n",
        "    \n",
        "    # save_samples\n",
        "    if step % 100 == 0:\n",
        "      sample_imgs(generator, noise_size, step)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jHnx_qUceZyc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define hyperparameters"
      ]
    },
    {
      "metadata": {
        "id": "1-ePrmDUVBYM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%rm -r /content/images\n",
        "%mkdir /content/images\n",
        "noise_size = 100\n",
        "img_shape = 28, 28\n",
        "batch_size = 64\n",
        "steps = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lhkkM5ctecbb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Generate the models"
      ]
    },
    {
      "metadata": {
        "id": "FCr5cDHOZCdW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator = build_generator(noise_size, img_shape)\n",
        "discriminator = build_discriminator(img_shape)\n",
        "compiled_models = get_compiled_models(generator, discriminator, noise_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zTkuRejSefba",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train the models"
      ]
    },
    {
      "metadata": {
        "id": "JznD-Lt6Y2h_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train(compiled_models, noise_size, img_shape, batch_size, steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7BDEKYo9ehjq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Display samples"
      ]
    },
    {
      "metadata": {
        "id": "ia-xsFkmVxTc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Image('/content/images/%d.png' % 800)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}