{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple_GAN_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Machine-Learning-Tokyo/DL-workshop-series/blob/master/Simple_GAN_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "KlRx5ymdZG0E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ]
    },
    {
      "metadata": {
        "id": "tHZUZmOUNEoJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, BatchNormalization, Reshape, Flatten\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.datasets import mnist\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-YA77SHFtXaq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import the necessary functions\n",
        "This cell will import the predefined functions needed for the execution of the notebook.\n",
        "\n",
        "If you want to call a function that is defined in this notebook, delete the headed underscore from the function's name"
      ]
    },
    {
      "metadata": {
        "id": "dLJB3bGWtATM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%rm -r adf93f9900d1dcfb6d76c83adec74a85\n",
        "!git clone https://gist.github.com/dkatsios/adf93f9900d1dcfb6d76c83adec74a85.git\n",
        "!pip install import_ipynb\n",
        "import import_ipynb\n",
        "%cd /content/adf93f9900d1dcfb6d76c83adec74a85\n",
        "from simple_gan_gist import *\n",
        "%cd /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uvvPV_WIZoR2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to build the generator"
      ]
    },
    {
      "metadata": {
        "id": "6gqJ4ZrmNHve",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _build_generator(noise_size, img_shape):\n",
        "  \"\"\"\n",
        "  function that takes as input\n",
        "  the noise_size (integer) and the img_shape (tuple of integers)\n",
        "  and returns a keras Model.\n",
        "  The model has 3 blocks of Dense, BatchNormalization and LeakyReLU layers.\n",
        "  The units at the Dense layers are 256, 512 and 1024 respectively.\n",
        "  The alpha parameter at the LeakyReLU layers is 0.2.\n",
        "  The activation of the last layer is tanh.\n",
        "  The model (generator) takes as input a tensor of shape (noise_size,)\n",
        "  and returns a tensor of shape img_shape.\n",
        "  \"\"\"\n",
        "  \n",
        "  noise = Input((noise_size,))\n",
        "  \n",
        "  x = Dense(256)(noise)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  \n",
        "  # TODO add 2 more blocks at the model\n",
        "  \n",
        "  x = Dense(np.prod(img_shape), activation='tanh')(x)\n",
        "  img = Reshape(img_shape)(x)\n",
        "  \n",
        "  generator = Model(noise, img)\n",
        "  return generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ooEwRbP8eLgw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to build the discriminator"
      ]
    },
    {
      "metadata": {
        "id": "UysJTIlPOlZS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _build_discriminator(img_shape):\n",
        "  \"\"\"\n",
        "  function that takes as input the img_shape (tuple of integers)\n",
        "  and returns a keras Model.\n",
        "  The model has 3 blocks of Dense and LeakyReLU layers.\n",
        "  The units at the Dense layers are 1024, 512, and 256 respectively.\n",
        "  The alpha parameter at the LeakyReLU layers is 0.2\n",
        "  The activation of the last layer is sigmoid.\n",
        "  The model (discriminator) takes as input a tensor of shape img_shape\n",
        "  and returns a tensor of shape 1\n",
        "  \"\"\"\n",
        "  \n",
        "  img = Input(img_shape)\n",
        "  x = Flatten()(img)\n",
        "  \n",
        "  x = Dense(1024)(x)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  \n",
        "  # TODO add 2 more blocks at the model\n",
        "  \n",
        "  validity = Dense(1, activation='sigmoid')(x)\n",
        "  \n",
        "  discriminator = Model(img, validity)\n",
        "  return discriminator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uxDM6ldueOte",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to compile the models"
      ]
    },
    {
      "metadata": {
        "id": "gEfTuy93PRNb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _get_compiled_models(generator, discriminator, noise_size):\n",
        "  \"\"\"\n",
        "  function that takes as input\n",
        "  the generator (keras.Model)\n",
        "  the discriminator (keras.Model)\n",
        "  and the noise_size (integer)\n",
        "  and return the generator, the compiled discriminator and the compiled comnbined models.\n",
        "  The combined model takes as input noise (tensor of shape (noise_size,))\n",
        "  and outputs the validity (output of the discriminator)\n",
        "  of the internally generated image (output of the generator).\n",
        "  For both models the optimizer is Adam with learning rate 0.0002 and beta_1 0.5\n",
        "  and the loss function is binary_crossentropy.\n",
        "  The discriminator has accuracy as metric.\n",
        "  \"\"\"\n",
        "  \n",
        "  optimizer = Adam(0.0002, 0.5)\n",
        "  \n",
        "  discriminator.compile(optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  discriminator.trainable = False\n",
        "  \n",
        "  noise = Input((noise_size,))\n",
        "  img = generator(noise)\n",
        "  validity = discriminator(img)\n",
        "  \n",
        "  # TODO create and compile the combined model\n",
        "  \n",
        "  return generator, discriminator, combined"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ocu71YfmeSIH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to sample and save generated images"
      ]
    },
    {
      "metadata": {
        "id": "X4-ejg8UTwqV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _sample_imgs(generator, noise_size, step):\n",
        "  \"\"\"\n",
        "  function that takes as input the generator (keras.Model), the noise_size (integer)\n",
        "  and the step (integer) and generates and saves samples of the generated images.\n",
        "  The images are in a 5x5 grid and are saved at ./images/{step}.png\n",
        "  \"\"\"\n",
        "  \n",
        "  r, c = 5, 5\n",
        "  noise = np.random.normal(0, 1, (r*c, noise_size))\n",
        "  imgs = generator.predict(noise)\n",
        "  imgs = imgs / 2 + 0.5\n",
        "  \n",
        "  fig, axs = plt.subplots(r, c)\n",
        "  cnt = 0\n",
        "  for i in range(r):\n",
        "    for j in range(c):\n",
        "      axs[i, j].imshow(imgs[cnt], cmap='gray')\n",
        "      axs[i, j].axis('off')\n",
        "      cnt += 1\n",
        "  fig.savefig('./images/%d.png' % step)\n",
        "  plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K3ofIxpleVoc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to train the models"
      ]
    },
    {
      "metadata": {
        "id": "wHI7xwGMQRAW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _train(models, noise_size, img_shape, batch_size, steps):\n",
        "  \"\"\"\n",
        "  function that takes as input the models (tuple of generator, discriminator, combined),\n",
        "  the noise_size, the img_shape, the batch_size and the steps and trains the models\n",
        "  for this number of steps on batches of size batch_size.\n",
        "  The training data are from mnist (keras.datasets).\n",
        "  For preprocessing, the data are normalized in [-1, 1] (original in [0, 255]).\n",
        "  Every 100 steps the models loss and accuracy is printed and samples are saved.\n",
        "  \"\"\"\n",
        "  generator, discriminator, combined = models\n",
        "  # get real data\n",
        "  (X_train, _), (X_val, _) = mnist.load_data()\n",
        "  \n",
        "  # TODO concatenate and normalize mnist images\n",
        "  \n",
        "  for step in range(1, steps + 1):\n",
        "    # train discriminator\n",
        "    inds = np.random.randint(0, mnist_imgs.shape[0], batch_size)\n",
        "    real_imgs = mnist_imgs[inds]\n",
        "    real_validity = np.ones(batch_size)\n",
        "    \n",
        "    noise = np.random.normal(0, 1, (batch_size, noise_size))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "    gen_validity = np.zeros(batch_size)\n",
        "    \n",
        "    r_loss = discriminator.train_on_batch(real_imgs, real_validity)\n",
        "    g_loss = discriminator.train_on_batch(gen_imgs, gen_validity)\n",
        "    disc_loss = np.add(r_loss, g_loss) / 2\n",
        "    \n",
        "    # train generator\n",
        "    noise = np.random.normal(0, 1, (batch_size, noise_size))\n",
        "    gen_validity = np.ones(batch_size)\n",
        "    \n",
        "    # TODO train the combined model\n",
        "    \n",
        "    #print progress\n",
        "    if step % 100 == 0:\n",
        "      print('step: %d, D_loss: %f, D_accuracy: %.2f%%, G_loss: %f' % (step, disc_loss[0],\n",
        "                                                                      disc_loss[1] * 100, gen_loss))\n",
        "    \n",
        "    # save_samples\n",
        "    if step % 100 == 0:\n",
        "      sample_imgs(generator, noise_size, step)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jHnx_qUceZyc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define hyperparameters"
      ]
    },
    {
      "metadata": {
        "id": "1-ePrmDUVBYM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%rm -r /content/images\n",
        "%mkdir /content/images\n",
        "noise_size = 100\n",
        "img_shape = 28, 28\n",
        "batch_size = 64\n",
        "steps = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lhkkM5ctecbb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Generate the models"
      ]
    },
    {
      "metadata": {
        "id": "FCr5cDHOZCdW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator = build_generator(noise_size, img_shape)\n",
        "discriminator = build_discriminator(img_shape)\n",
        "compiled_models = get_compiled_models(generator, discriminator, noise_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zTkuRejSefba",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train the models"
      ]
    },
    {
      "metadata": {
        "id": "JznD-Lt6Y2h_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train(compiled_models, noise_size, img_shape, batch_size, steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7BDEKYo9ehjq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Display samples"
      ]
    },
    {
      "metadata": {
        "id": "ia-xsFkmVxTc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Image('/content/images/%d.png' % 1000)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}